// Signature file for parser generated by fsyacc
module Parser
type token = 
  | T_NAT
  | T_ATOM
  | T_PAIR
  | LAMBDA
  | EOF
  | L_PAREN
  | R_PAREN
  | CONS
  | CAR
  | CDR
  | PLUS
  | ADD1
  | CLAIM
  | ZERO
  | DEFINE
  | NAT of (uint32)
  | ATOM of (string)
  | NAME of (string)
type tokenId = 
    | TOKEN_T_NAT
    | TOKEN_T_ATOM
    | TOKEN_T_PAIR
    | TOKEN_LAMBDA
    | TOKEN_EOF
    | TOKEN_L_PAREN
    | TOKEN_R_PAREN
    | TOKEN_CONS
    | TOKEN_CAR
    | TOKEN_CDR
    | TOKEN_PLUS
    | TOKEN_ADD1
    | TOKEN_CLAIM
    | TOKEN_ZERO
    | TOKEN_DEFINE
    | TOKEN_NAT
    | TOKEN_ATOM
    | TOKEN_NAME
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
    | NONTERM_typ
    | NONTERM_value
    | NONTERM_both
    | NONTERM_name_fields
    | NONTERM_statement_list
    | NONTERM_stmntbody
    | NONTERM_stmnt
    | NONTERM_prog
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> FSharp.Text.Lexing.LexBuffer<'cty> -> (AST.Prog) 
